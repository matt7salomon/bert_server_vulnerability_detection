{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Zwb6WmkbANp",
        "outputId": "6e435f28-be5d-4807-e33e-e59af2733f1e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# URL of the GitHub raw file\n",
        "url = 'https://raw.githubusercontent.com/elastic/examples/refs/heads/master/Common%20Data%20Formats/apache_logs/apache_logs'\n",
        "\n",
        "# Send a GET request to fetch the data\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    data = response.text\n",
        "    print(data[:5500])  # Print the first 500 characters as a sample\n",
        "else:\n",
        "    print(f\"Failed to retrieve data. Status code: {response.status_code}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFaCV1xwi8Tk",
        "outputId": "07db7df4-4b37-48df-d72f-31e663db88ee"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83.149.9.216 - - [17/May/2015:10:05:03 +0000] \"GET /presentations/logstash-monitorama-2013/images/kibana-search.png HTTP/1.1\" 200 203023 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n",
            "83.149.9.216 - - [17/May/2015:10:05:43 +0000] \"GET /presentations/logstash-monitorama-2013/images/kibana-dashboard3.png HTTP/1.1\" 200 171717 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n",
            "83.149.9.216 - - [17/May/2015:10:05:47 +0000] \"GET /presentations/logstash-monitorama-2013/plugin/highlight/highlight.js HTTP/1.1\" 200 26185 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n",
            "83.149.9.216 - - [17/May/2015:10:05:12 +0000] \"GET /presentations/logstash-monitorama-2013/plugin/zoom-js/zoom.js HTTP/1.1\" 200 7697 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n",
            "83.149.9.216 - - [17/May/2015:10:05:07 +0000] \"GET /presentations/logstash-monitorama-2013/plugin/notes/notes.js HTTP/1.1\" 200 2892 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n",
            "83.149.9.216 - - [17/May/2015:10:05:34 +0000] \"GET /presentations/logstash-monitorama-2013/images/sad-medic.png HTTP/1.1\" 200 430406 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n",
            "83.149.9.216 - - [17/May/2015:10:05:57 +0000] \"GET /presentations/logstash-monitorama-2013/css/fonts/Roboto-Bold.ttf HTTP/1.1\" 200 38720 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n",
            "83.149.9.216 - - [17/May/2015:10:05:50 +0000] \"GET /presentations/logstash-monitorama-2013/css/fonts/Roboto-Regular.ttf HTTP/1.1\" 200 41820 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n",
            "83.149.9.216 - - [17/May/2015:10:05:24 +0000] \"GET /presentations/logstash-monitorama-2013/images/frontend-response-codes.png HTTP/1.1\" 200 52878 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n",
            "83.149.9.216 - - [17/May/2015:10:05:50 +0000] \"GET /presentations/logstash-monitorama-2013/images/kibana-dashboard.png HTTP/1.1\" 200 321631 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n",
            "83.149.9.216 - - [17/May/2015:10:05:46 +0000] \"GET /presentations/logstash-monitorama-2013/images/Dreamhost_logo.svg HTTP/1.1\" 200 2126 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n",
            "83.149.9.216 - - [17/May/2015:10:05:11 +0000] \"GET /presentations/logstash-monitorama-2013/images/kibana-dashboard2.png HTTP/1.1\" 200 394967 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n",
            "83.149.9.216 - - [17/May/2015:10:05:19 +0000] \"GET /presentations/logstash-monitorama-2013/images/apache-icon.gif HTTP/1.1\" 200 8095 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n",
            "83.149.9.216 - - [17/May/2015:10:05:33 +0000] \"GET /presentations/logstash-monitorama-2013/images/nagios-sms5.png HTTP/1.1\" 200 78075 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n",
            "83.149.9.216 - - [17/May/2015:10:05:00 +0000] \"GET /presentations/logstash-monitorama-2013/images/redis.png HTTP/1.1\" 200 25230 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n",
            "83.149.9.216 - - [17/May/2015:10:05:25 +0000] \"GET /presentations/logstash-monitorama-2013/images/elasticsearch.png HTTP/1.1\" 200 8026 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n",
            "83.149.9.216 - - [17/May/2015:10:05:59 +0000] \"GET /presentations/logstash-monitorama-2013/images/logstashbook.png HTTP/1.1\" 200 54662 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "# Split the long string into individual log entries\n",
        "log_lines = data.strip().split('\\n')\n",
        "\n",
        "# Regex to identify GET and POST requests\n",
        "logs = []\n",
        "\n",
        "# Preprocessing function to identify and separate GET and POST requests\n",
        "def create_requests(log_line):\n",
        "    \"\"\"\n",
        "    Creates requests\n",
        "    \"\"\"\n",
        "    logs.append(log_line)\n",
        "\n",
        "# Process each log line\n",
        "for log in log_lines:\n",
        "    create_requests(log)\n",
        "\n",
        "# Results\n",
        "print(\"\\n Requests:\")\n",
        "for req in logs[0:5]:\n",
        "    print(req)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dec84lDW2B2L",
        "outputId": "294de4e8-bc8f-4ca1-f3e9-35595b6c5d0d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Requests:\n",
            "83.149.9.216 - - [17/May/2015:10:05:03 +0000] \"GET /presentations/logstash-monitorama-2013/images/kibana-search.png HTTP/1.1\" 200 203023 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n",
            "83.149.9.216 - - [17/May/2015:10:05:43 +0000] \"GET /presentations/logstash-monitorama-2013/images/kibana-dashboard3.png HTTP/1.1\" 200 171717 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n",
            "83.149.9.216 - - [17/May/2015:10:05:47 +0000] \"GET /presentations/logstash-monitorama-2013/plugin/highlight/highlight.js HTTP/1.1\" 200 26185 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n",
            "83.149.9.216 - - [17/May/2015:10:05:12 +0000] \"GET /presentations/logstash-monitorama-2013/plugin/zoom-js/zoom.js HTTP/1.1\" 200 7697 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n",
            "83.149.9.216 - - [17/May/2015:10:05:07 +0000] \"GET /presentations/logstash-monitorama-2013/plugin/notes/notes.js HTTP/1.1\" 200 2892 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Anomaly Detection with Autoencoders\n",
        "\n",
        "\t•\tAutoencoders are neural networks that try to compress the input into a smaller representation (encoding) and then reconstruct the original input from the encoding (decoding).\n",
        "\t•\tFor log analysis, autoencoders can be trained to reconstruct “normal” logs. If the autoencoder struggles to reconstruct a log, it may indicate an anomaly or vulnerability.\n"
      ],
      "metadata": {
        "id": "ymfOW9WlkUre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logs = logs[0:20]"
      ],
      "metadata": {
        "id": "Lo6hlD6f5v_j"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Time decorator to measure execution time\n",
        "def timer_decorator(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end_time = time.time()\n",
        "        print(f\"{func.__name__} took {end_time - start_time:.4f} seconds.\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "# # Sample log lines (as an example)\n",
        "# logs = [\n",
        "#     '83.149.9.216 - - [17/May/2015:10:05:03 +0000] \"GET /presentations/logstash-monitorama-2013/images/kibana-search.png HTTP/1.1\" 200 203023 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"',\n",
        "#     '83.149.9.216 - - [17/May/2015:10:05:43 +0000] \"GET /presentations/logstash-monitorama-2013/images/kibana-dashboard3.png HTTP/1.1\" 200 171717 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"',\n",
        "#     '83.149.9.216 - - [17/May/2015:10:05:47 +0000] \"GET /presentations/logstash-monitorama-2013/plugin/highlight/highlight.js HTTP/1.1\" 200 26185 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"',\n",
        "# ]\n",
        "\n",
        "@timer_decorator\n",
        "def preprocess_logs(logs):\n",
        "    \"\"\"\n",
        "    Extract key components from multiple access log lines and return as a DataFrame.\n",
        "    \"\"\"\n",
        "    log_pattern = r'(?P<ip>[\\d.]+) - - \\[(?P<time>[^\\]]+)\\] \"(?P<method>[A-Z]+) (?P<url>[^\\s]+) HTTP/[0-9.]+\" (?P<status_code>\\d+) (?P<size>\\d+) \"(?P<referrer>[^\"]*)\" \"(?P<user_agent>[^\"]*)\"'\n",
        "\n",
        "    parsed_logs = []\n",
        "    for log in logs:\n",
        "        match = re.match(log_pattern, log)\n",
        "        if match:\n",
        "            parsed_logs.append(match.groupdict())\n",
        "\n",
        "    log_df = pd.DataFrame(parsed_logs)\n",
        "    print(f\"Processed {len(logs)} logs into DataFrame of shape: {log_df.shape}\")\n",
        "    return log_df\n",
        "\n",
        "# BERT tokenizer and model\n",
        "@timer_decorator\n",
        "def initialize_bert():\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "    print(\"BERT initialized.\")\n",
        "    return tokenizer, bert_model\n",
        "\n",
        "# Function to encode log data using BERT\n",
        "@timer_decorator\n",
        "def encode_log_bert(log_df, tokenizer, model):\n",
        "    \"\"\"\n",
        "    Tokenizes and encodes the log features using BERT.\n",
        "    \"\"\"\n",
        "    tokenized_logs = []\n",
        "\n",
        "    for _, row in log_df.iterrows():\n",
        "        log_text = f\"URL: {row['url']} Status: {row['status_code']} Agent: {row['user_agent']}\"\n",
        "        inputs = tokenizer(log_text, return_tensors='pt', truncation=True, padding=True)\n",
        "        outputs = model(**inputs)\n",
        "        log_embedding = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
        "        tokenized_logs.append(log_embedding)\n",
        "\n",
        "    print(f\"Encoded {len(tokenized_logs)} logs.\")\n",
        "    return tokenized_logs\n",
        "\n",
        "@timer_decorator\n",
        "def initialize_classifier(input_dim):\n",
        "    class LogClassifier(nn.Module):\n",
        "        def __init__(self, input_dim):\n",
        "            super(LogClassifier, self).__init__()\n",
        "            self.fc1 = nn.Linear(input_dim, 128)\n",
        "            self.fc2 = nn.Linear(128, 64)\n",
        "            self.fc3 = nn.Linear(64, 1)\n",
        "            self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = torch.relu(self.fc1(x))\n",
        "            x = torch.relu(self.fc2(x))\n",
        "            x = self.sigmoid(self.fc3(x))\n",
        "            return x\n",
        "\n",
        "    model = LogClassifier(input_dim)\n",
        "    print(\"Classifier initialized.\")\n",
        "    return model\n",
        "\n",
        "@timer_decorator\n",
        "def train_model(model, log_embeddings_tensor, labels_tensor, num_epochs=10):\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        outputs = model(log_embeddings_tensor)\n",
        "        loss = criterion(outputs, labels_tensor)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Workflow\n",
        "log_df = preprocess_logs(logs)\n",
        "tokenizer, bert_model = initialize_bert()\n",
        "log_embeddings = encode_log_bert(log_df, tokenizer, bert_model)\n",
        "\n",
        "# Convert embeddings to a NumPy array and tensors\n",
        "log_embeddings = np.vstack(log_embeddings)\n",
        "log_embeddings_tensor = torch.tensor(log_embeddings, dtype=torch.float32)\n",
        "\n",
        "lbl = np.zeros([len(logs)])\n",
        "lbl[13] = 1\n",
        "\n",
        "\n",
        "# Example labels (to be replaced with actual labels)\n",
        "labels = torch.tensor(lbl)\n",
        "labels_tensor = labels.float().view(-1, 1)\n",
        "\n",
        "# Initialize and train the classifier\n",
        "model = initialize_classifier(input_dim=log_embeddings.shape[1])\n",
        "train_model(model, log_embeddings_tensor, labels_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y72RZ7gQkUeC",
        "outputId": "6446c555-1a54-43f9-a63f-1c6afad13b64"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20 logs into DataFrame of shape: (20, 8)\n",
            "preprocess_logs took 0.0036 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT initialized.\n",
            "initialize_bert took 0.4861 seconds.\n",
            "Encoded 20 logs.\n",
            "encode_log_bert took 12.3378 seconds.\n",
            "Classifier initialized.\n",
            "initialize_classifier took 0.0017 seconds.\n",
            "Epoch [1/10], Loss: 0.6938\n",
            "Epoch [2/10], Loss: 0.6322\n",
            "Epoch [3/10], Loss: 0.5827\n",
            "Epoch [4/10], Loss: 0.5322\n",
            "Epoch [5/10], Loss: 0.4791\n",
            "Epoch [6/10], Loss: 0.4253\n",
            "Epoch [7/10], Loss: 0.3727\n",
            "Epoch [8/10], Loss: 0.3247\n",
            "Epoch [9/10], Loss: 0.2830\n",
            "Epoch [10/10], Loss: 0.2494\n",
            "train_model took 0.0402 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7eZ2X9sX6Wl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Sample log embeddings (You can replace this with your BERT embeddings)\n",
        "# log_embeddings = np.random.randn(1000, 128)  # Assuming 1000 logs with 128 features each\n",
        "\n",
        "# Preprocess the embeddings\n",
        "scaler = StandardScaler()\n",
        "log_embeddings_scaled = scaler.fit_transform(log_embeddings)\n",
        "\n",
        "# Convert to tensor\n",
        "log_embeddings_tensor = torch.tensor(log_embeddings_scaled, dtype=torch.float32)\n",
        "\n",
        "# Define the autoencoder\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(32, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the autoencoder\n",
        "input_dim = log_embeddings_tensor.shape[1]\n",
        "autoencoder = Autoencoder(input_dim)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    output = autoencoder(log_embeddings_tensor)\n",
        "    loss = criterion(output, log_embeddings_tensor)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# After training, you can use the reconstruction error to detect anomalies:\n",
        "reconstructed = autoencoder(log_embeddings_tensor).detach().numpy()\n",
        "mse = np.mean((log_embeddings_scaled - reconstructed) ** 2, axis=1)\n",
        "\n",
        "# Define a threshold to classify anomalies (e.g., values above threshold are anomalies)\n",
        "threshold = np.percentile(mse, 95)\n",
        "anomalies = mse > threshold\n",
        "print('anomalies: ',pd.Series(logs)[anomalies])\n",
        "print(f\"Number of anomalies detected: {np.sum(anomalies)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raaMWB6Pi9I1",
        "outputId": "7757d597-f10e-4d5e-eb79-505a208c8d19"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/50], Loss: 0.9182\n",
            "Epoch [20/50], Loss: 0.7303\n",
            "Epoch [30/50], Loss: 0.5255\n",
            "Epoch [40/50], Loss: 0.3700\n",
            "Epoch [50/50], Loss: 0.2651\n",
            "anomalies:  13    83.149.9.216 - - [17/May/2015:10:05:33 +0000] ...\n",
            "dtype: object\n",
            "Number of anomalies detected: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How It Works:\n",
        "\n",
        "\t•\tAutoencoder Training: The autoencoder is trained to reconstruct the original log embeddings. If a log is unusual, the autoencoder will fail to reconstruct it accurately, resulting in a high reconstruction error.\n",
        "\t•\tAnomaly Detection: Logs with a high reconstruction error are flagged as anomalies."
      ],
      "metadata": {
        "id": "qCldpm4-khCn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Clustering for Anomaly Detection (DBSCAN, K-Means)\n",
        "\n",
        "\t•\tClustering algorithms like DBSCAN or K-Means can be used to group similar logs together. Outliers or logs that don’t fit well into clusters can be treated as anomalies or potential vulnerabilities.\n",
        "\t•\tDBSCAN is particularly useful because it can detect outliers that don’t belong to any cluster."
      ],
      "metadata": {
        "id": "aLFCwlyAkjuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Assume log_embeddings is a matrix where each row is a log embedding\n",
        "# log_embeddings = np.random.randn(1000, 128)\n",
        "\n",
        "# Scale the embeddings\n",
        "scaler = StandardScaler()\n",
        "log_embeddings_scaled = scaler.fit_transform(log_embeddings)\n",
        "\n",
        "# Apply DBSCAN clustering\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=10)\n",
        "labels = dbscan.fit_predict(log_embeddings_scaled)\n",
        "\n",
        "# Identify outliers (DBSCAN labels outliers as -1)\n",
        "outliers = labels == -1\n",
        "print(f\"Number of outliers detected: {np.sum(outliers)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLcQZ9mVkgy_",
        "outputId": "6c238720-7f5e-41c6-b923-7945a3a3d250"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of outliers detected: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How It Works:\n",
        "\n",
        "\t•\tClustering: DBSCAN groups logs that are similar to each other based on the distance between their embeddings. Logs that don’t fit into any cluster are treated as outliers.\n",
        "\t•\tOutliers: Outliers could represent unusual behavior or potential vulnerabilities."
      ],
      "metadata": {
        "id": "Ai7_lZYxks0Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Isolation Forest\n",
        "\n",
        "\t•\tIsolation Forest is an ensemble-based anomaly detection algorithm that isolates anomalies by randomly partitioning data.\n",
        "\t•\tIt works well for high-dimensional data like log embeddings."
      ],
      "metadata": {
        "id": "GmDmdc2okvFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Assume log_embeddings is a matrix where each row is a log embedding\n",
        "# log_embeddings = np.random.randn(1000, 128)\n",
        "\n",
        "# Scale the embeddings\n",
        "scaler = StandardScaler()\n",
        "log_embeddings_scaled = scaler.fit_transform(log_embeddings)\n",
        "\n",
        "# Fit Isolation Forest\n",
        "iso_forest = IsolationForest(contamination=0.05)\n",
        "iso_forest.fit(log_embeddings_scaled)\n",
        "\n",
        "# Predict anomalies\n",
        "anomalies = iso_forest.predict(log_embeddings_scaled) == -1\n",
        "print('anomalies: ',pd.Series(logs)[anomalies])\n",
        "print(f\"Number of anomalies detected: {np.sum(anomalies)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHPBJu5akXkB",
        "outputId": "53347593-d6f0-49ef-844d-794e0c95df7a"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anomalies:  19    83.149.9.216 - - [17/May/2015:10:05:24 +0000] ...\n",
            "dtype: object\n",
            "Number of anomalies detected: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "56Z0oQoVkxHm"
      },
      "execution_count": 61,
      "outputs": []
    }
  ]
}